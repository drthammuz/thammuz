{"user_input":{"prompt":"hej"}}
{"gpt_response":{"id":"chatcmpl-8OraMg9FdSYTKeJlOH5ZG3ddgbTJ3","object":"chat.completion","created":1700936546,"model":"gpt-4-1106-preview","choices":[{"index":0,"message":{"role":"assistant","content":"```mermaid\nflowchart LR\n  start(Hej) --> option1{Is the greeting casual?}\n  option1 -- Yes --> casualFlow[Select casual response]\n  option1 -- No --> formalFlow[Select formal response]\n  \n  casualFlow --> response1(Tjena!)\n  casualFlow --> response2(Hall\u00e5!)\n  casualFlow --> response3(Hejsan!)\n\n  formalFlow --> response4(God dag.)\n  formalFlow --> response5(Goddag, hur m\u00e5r Ni?)\n\n  response1 --> END1((END))\n  response2 --> END2((END))\n  response3 --> END3((END))\n  response4 --> END4((END))\n  response5 --> END5((END))\n\n  classDef casualColor fill:#f96,stroke:#333,stroke-width:2px;\n  classDef formalColor fill:#9f6,stroke:#333;\n  class casualFlow casualColor;\n  class formalFlow,option1 formalColor;\n```"},"finish_reason":"stop"}],"usage":{"prompt_tokens":136,"completion_tokens":205,"total_tokens":341},"system_fingerprint":"fp_a24b4d720c"}}
{"mermaid_syntax":"flowchart LR\n  start(Hej) --> option1{Is the greeting casual?}\n  option1 -- Yes --> casualFlow[Select casual response]\n  option1 -- No --> formalFlow[Select formal response]\n  \n  casualFlow --> response1(Tjena!)\n  casualFlow --> response2(Hall\u00e5!)\n  casualFlow --> response3(Hejsan!)\n\n  formalFlow --> response4(God dag.)\n  formalFlow --> response5(Goddag, hur m\u00e5r Ni?)\n\n  response1 --> END1((END))\n  response2 --> END2((END))\n  response3 --> END3((END))\n  response4 --> END4((END))\n  response5 --> END5((END))\n\n  classDef casualColor fill:#f96,stroke:#333,stroke-width:2px;\n  classDef formalColor fill:#9f6,stroke:#333;\n  class casualFlow casualColor;\n  class formalFlow,option1 formalColor;"}
{"mermaid_cli_response":"https:\/\/laravel.panacean.it\/cli_images\/image_1700936553389.svg"}
