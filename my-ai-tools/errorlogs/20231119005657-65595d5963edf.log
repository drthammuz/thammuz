{"user_input":"a->b"}
{"gpt_response":{"id":"chatcmpl-8MQPJqOKiuziBlA2GTwCVvn4iqags","object":"chat.completion","created":1700355417,"model":"gpt-4-1106-preview","choices":[{"index":0,"message":{"role":"assistant","content":"```mermaid\nflowchart TB\n    startNode([Start]) --> a\n    a --> b\n    b --> decision{Is the task complete?}\n    decision --> |Yes| processEND[Process END]\n    decision --> |No| a\n    processEND --> stopNode([Stop])\n```"},"finish_reason":"stop"}],"usage":{"prompt_tokens":423,"completion_tokens":63,"total_tokens":486},"system_fingerprint":"fp_a24b4d720c"}}
{"mermaid_syntax":"flowchart TB\n    startNode([Start]) --> a\n    a --> b\n    b --> decision{Is the task complete?}\n    decision --> |Yes| processEND[Process END]\n    decision --> |No| a\n    processEND --> stopNode([Stop])"}
{"mermaid_cli_response":{"svgUrl":"http:\/\/135.181.158.154\/mermaid_images\/image_1700355419330.svg","mmdContent":"flowchart TB\n    startNode([Start]) --> a\n    a --> b\n    b --> decision{Is the task complete?}\n    decision --> |Yes| processEND[Process END]\n    decision --> |No| a\n    processEND --> stopNode([Stop])","usedSyntax":"flowchart TB\n    startNode([Start]) --> a\n    a --> b\n    b --> decision{Is the task complete?}\n    decision --> |Yes| processEND[Process END]\n    decision --> |No| a\n    processEND --> stopNode([Stop])"}}
